package test.resources.test_jobs; import org.apache.spark.SparkConf; import java.util.stream.Stream;
import java.util.Map;
import java.util.AbstractMap.SimpleEntry;
 import java.util.stream.Stream; import org.apache.spark.api.java.JavaSparkContext; import java.util.AbstractMap.SimpleEntry; import java.util.Arrays; public class SparkJavaWordCountJava8Translated { public static void main(String[] args) { SparkConf conf = new SparkConf().setAppName("SparkJavaWordCountJava8Translated"); JavaSparkContext sc = new JavaSparkContext(conf); Stream<String> textFile = sc.textFile("swift2d://data1.lvm/hamlet.txt"); Map<String, Integer> counts = textFile.flatMap(s -> Arrays.stream(s.split(" "))).map(word -> word.replaceAll("[^a-zA-Z]", "").toLowerCase().trim()).map(word -> new SimpleEntry<String, Integer>(word, 1)).collect(java.util.stream.Collectors.groupingBy(SimpleEntry<String, Integer>::getKey, java.util.stream.Collectors.counting())); counts.saveAsTextFile("swift2d://data1.lvm/hamlet_result.txt"); } }
