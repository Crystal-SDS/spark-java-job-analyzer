package test.resources.test_jobs; import java.util.ArrayList; import java.util.List; import java.util.regex.Pattern; import java.util.AbstractMap.SimpleEntry; import com.google.common.collect.Lists; import java.util.stream.Stream;
import java.util.Map;
import java.util.AbstractMap.SimpleEntry;

import java.util.Map;
import java.util.AbstractMap.SimpleEntry;

import java.util.Map;
import java.util.AbstractMap.SimpleEntry;
 import java.util.stream.Stream; import org.apache.spark.api.java.function.Function2; import org.apache.spark.sql.SparkSession; public final class SparkJavaPageRankJava8Translated { private static final Pattern SPACES = Pattern.compile("\\s+"); static void showWarning() { String warning = "WARN: This is a naive implementation of PageRank " + "and is given as an example! \n" + "Please use the PageRank implementation found in " + "org.apache.spark.graphx.lib.PageRank for more conventional use."; System.err.println(warning); } private static class Sum implements Function2<Double, Double, Double> { @Override public Double call(Double a, Double b) { return a + b; } } public static void main(String[] args) throws Exception { if (args.length < 2) { System.err.println("Usage: JavaPageRank <file> <number_of_iterations>"); System.exit(1); } showWarning(); SparkSession spark = SparkSession.builder().appName("JavaPageRank").getOrCreate(); Stream<String> lines = spark.read().textFile(args[0]).javaRDD(); JavaPairRDD<String, List<String>> links = lines.map(s -> { String[] parts = s.split("\\s+"); return new SimpleEntry<String, String>(parts[0], parts[1]); }).distinct(); Map<String, Double> ranks = links; for (int current = 0; current < Integer.parseInt(args[1]); current++) { Map<String, Double> contribs = links.join(ranks).values().flatMapToPair(s -> { int urlCount = Lists.size(s._1()); List<Tuple2<String, Double>> results = new ArrayList<>(); for (String n : s._1) { results.add(new Tuple2<>(n, s._2() / urlCount)); } return results.iterator(); }); ranks = contribs.reduceByKey(new Sum()); } List<Tuple2<String, Double>> output = ranks; for (Tuple2<?, ?> tuple : output) { System.out.println(tuple._1() + " has rank: " + tuple._2() + "."); } spark.stop(); } }
